# -*- coding: utf-8 -*-
"""Problem1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/183GQphmqBPTrUpnKnTnmeHri7JDin4Y4
"""

!pip install datasets

from datasets import load_dataset
ds = load_dataset("zh-plus/tiny-imagenet")

print(ds)  # Check dataset structure
print(ds["train"].features)  # Check available fields

import random
import pandas as pd

# Extract my own dataset
mydata = ds["train"]

# Get unique class labels
all_classes = list(set(mydata["label"]))
selected_classes = random.sample(all_classes, 100)  # Pick 100 random classes

# Filter dataset for selected classes
filtered_data = [ex for ex in mydata if ex["label"] in selected_classes]

# Group by class and pick 500 images per class
final_dataset = []
class_counts = {cls: 0 for cls in selected_classes}

for ex in filtered_data:
    if class_counts[ex["label"]] < 500:
        final_dataset.append(ex)
        class_counts[ex["label"]] += 1

# Convert to a DataFrame to check
df = pd.DataFrame(final_dataset)
print(df["label"].value_counts())  # Should show 500 images per class

import os
import random
import shutil
from PIL import Image
from tqdm import tqdm

# Ensure output directories exist
os.makedirs("tiny-imagenet/split/train", exist_ok=True)
os.makedirs("tiny-imagenet/split/test", exist_ok=True)
os.makedirs("tiny-imagenet/split/val", exist_ok=True)

def resize_and_crop(image_path):
    """Resize image (shorter side to 256px) and crop a 256x256 center patch."""
    with Image.open(image_path) as img:

        # Resize so that the shorter side is 256 pixels
        width, height = img.size
        if width < height:
            new_width = 256
            new_height = int(height * (256 / width))
        else:
            new_height = 256
            new_width = int(width * (256 / height))

        img = img.resize((new_width, new_height), Image.BICUBIC)

        # Center crop to 256x256
        left = (new_width - 256) // 2
        top = (new_height - 256) // 2
        img = img.crop((left, top, left + 256, top + 256))

        return img

import random

# Convert dataset to a list of dictionaries
mydata_list = list(mydata)  # Convert dataset to a list

# Shuffle dataset to ensure randomness
random.shuffle(mydata_list)

# Define dataset sizes
train_size = 30000
test_size = 10000
val_size = 10000

# Split into training, testing, and validation sets
train_data = mydata_list[:train_size]
test_data = mydata_list[train_size:train_size + test_size]
val_data = mydata_list[train_size + test_size:train_size + test_size + val_size]

# Verify sizes
print(f"Train: {len(train_data)}, Test: {len(test_data)}, Validation: {len(val_data)}")

import os
import torch
from PIL import Image
from tqdm import tqdm
from torchvision import transforms

def save_images(dataset, folder_name):
    for i, sample in tqdm(enumerate(dataset), total=len(dataset), desc=f"Processing {folder_name}"):
        try:
            label = sample["label"]
            image = sample["image"]

            # Ensure output directory exists
            output_dir = f"tiny-imagenet/split/{folder_name}/{label}"
            os.makedirs(output_dir, exist_ok=True)

            # Convert image if it's not already a PIL image
            if isinstance(image, str):  # If stored as file path
                image = Image.open(image)
            elif isinstance(image, torch.Tensor):  # If stored as tensor
                image = transforms.ToPILImage()(image)

            # Process and save
            processed_img = resize_and_crop(image)
            processed_img.save(os.path.join(output_dir, f"{i}.jpg"))

        except Exception as e:
            print(f"Error processing image {i}: {e}")

# Run the function
save_images(train_data, "train")
save_images(test_data, "test")
save_images(val_data, "val")

print("Dataset successfully split and processed!")

